{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python3-wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: DATABASE TABLES CREATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5318ffe6ed95>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5318ffe6ed95>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    CREATE EXTENSION pgcrypto;\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "CREATE EXTENSION pgcrypto;\n",
    "\n",
    "\n",
    "--\n",
    "-- Name: pub_review_paragraphs; Type: TABLE; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "CREATE TABLE public.pub_review_paragraphs (\n",
    "    id uuid DEFAULT public.gen_random_uuid() NOT NULL,\n",
    "    pub_url text NOT NULL,\n",
    "    paragraph_text text NOT NULL,\n",
    "    date_created timestamp with time zone NOT NULL,\n",
    "    date_updated timestamp with time zone NOT NULL,\n",
    "    username text NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "ALTER TABLE public.pub_review_paragraphs OWNER TO postgres;\n",
    "\n",
    "--\n",
    "-- Name: publication_urls; Type: TABLE; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "CREATE TABLE public.publication_urls (\n",
    "    id uuid DEFAULT public.gen_random_uuid() NOT NULL,\n",
    "    site_id uuid NULL,\n",
    "    date_created timestamp with time zone NOT NULL,\n",
    "    date_updated timestamp with time zone NOT NULL,\n",
    "    username text NOT NULL,\n",
    "    pub_url text NOT NULL,\n",
    "    is_scraped boolean DEFAULT false NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "ALTER TABLE public.publication_urls OWNER TO postgres;\n",
    "\n",
    "--\n",
    "-- Name: site_review_urls; Type: TABLE; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "CREATE TABLE public.site_review_urls (\n",
    "    id uuid DEFAULT public.gen_random_uuid() NOT NULL,\n",
    "    site_url text NOT NULL,\n",
    "    date_created timestamp with time zone NOT NULL,\n",
    "    date_updated timestamp with time zone NOT NULL,\n",
    "    username text NOT NULL\n",
    ");\n",
    "\n",
    "\n",
    "ALTER TABLE public.site_review_urls OWNER TO postgres;\n",
    "\n",
    "--\n",
    "-- Name: pub_review_paragraphs pub_review_paragraphs_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "ALTER TABLE ONLY public.pub_review_paragraphs\n",
    "    ADD CONSTRAINT pub_review_paragraphs_pkey PRIMARY KEY (id);\n",
    "\n",
    "\n",
    "--\n",
    "-- Name: publication_urls publication_urls_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "ALTER TABLE ONLY public.publication_urls\n",
    "    ADD CONSTRAINT publication_urls_pkey PRIMARY KEY (id);\n",
    "\n",
    "\n",
    "--\n",
    "-- Name: site_review_urls site_review_urls_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "ALTER TABLE ONLY public.site_review_urls\n",
    "    ADD CONSTRAINT site_review_urls_pkey PRIMARY KEY (id);\n",
    "    \n",
    "--\n",
    "-- Name: publication_urls fk_puburl_site; Type: FK CONSTRAINT; Schema: public; Owner: postgres\n",
    "--\n",
    "\n",
    "ALTER TABLE ONLY public.publication_urls\n",
    "    ADD CONSTRAINT fk_puburl_site FOREIGN KEY (site_id) REFERENCES public.site_review_urls(id);\n",
    "\n",
    "\n",
    "\n",
    "https://starkandwayne.com/blog/uuid-primary-keys-in-postgresql/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-056ae9006625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# method to get a connection to local PostgreSQL database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_conn_rds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# method to get a connection to local PostgreSQL database\n",
    "def get_conn_rds(): \n",
    "\n",
    "    try:\n",
    "        # connect to the postgresql database\n",
    "        print(\"Connecting to the PostgreSQL database...\")\n",
    "\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                  password = \"postgres123\",\n",
    "                                  host = \"localhost\", \n",
    "                                  port = \"5432\",\n",
    "                                  database = \"postgres\")\n",
    "\n",
    "        return connection\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "        \n",
    "conn = get_conn_rds()\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "\n",
    "#Insert into table : metacritic_review_urls. \n",
    "def insert_to_tbl_metacritic_review_urls(metacritic_href, username):\n",
    "    try:\n",
    "        conn = get_conn_rds()\n",
    "        cur = conn.cursor()\n",
    "        query_params_list = {'metacritic_href': metacritic_href, \n",
    "                             'date_created': datetime.datetime.now(),\n",
    "                             'date_updated': datetime.datetime.now(),\n",
    "                             'username': username}\n",
    "        sql = '''\n",
    "                INSERT INTO public.\"metacritic_review_urls\"(metacritic_href, date_created, date_updated, username)\n",
    "                        VALUES (%(metacritic_href)s, %(date_created)s, %(date_updated)s, %(username)s);\n",
    "                '''\n",
    "        \n",
    "        cur.execute(sql, query_params_list)\n",
    "\n",
    "        conn.commit()\n",
    "        \n",
    "        print(\"Successfully inserted a record\")\n",
    "\n",
    "        cur.close()\n",
    "        \n",
    "        print(\"Closing Connection.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 - You get urls for all movies on page1 page2 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import uuid\n",
    "import psycopg2\n",
    "\n",
    "links_page1 = []\n",
    "result_urls = []\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "site_movies_by_year_desc_url = 'https://www.metacritic.com/browse/movies/score/metascore/year/filtered?sort=desc'\n",
    "\n",
    "# webscraper method to first get all the urls on the above url where I'm filtering \"desc\" for current year 2020.\n",
    "# similarly, the above url can be changed to the year 2019. \n",
    "# The following method just scrapes all the review urls on page 1. I'll need to do the same for page2 and so on.\n",
    "def fetchandinsert_movie_releases_by_year_urls():\n",
    "    browser = webdriver.Chrome(\"/home/srini/pyprjs/scrpr/chromedriver\", options=options)\n",
    "    browser.get(site_movies_by_year_desc_url)\n",
    "    css_selector_metacritic_review_links = \"div.clamp-metascore\"\n",
    "    divs = browser.find_elements_by_css_selector(css_selector_metacritic_review_links)\n",
    "    for div in divs:\n",
    "        href_el = div.find_element_by_css_selector('a').get_attribute('href')\n",
    "        # inserts the scraped urls on the page into the database table :metacritics_review_urls\n",
    "        insert_to_metacritic_review_urls(href_el, 'Srini')\n",
    "        links_page1.append(href_el)\n",
    "    return links_page1\n",
    "\n",
    "result_urls = fetchandinsert_movie_releases_by_year_urls()\n",
    "print(len(result_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - read the urls from the database and now for each of these urls - we'll need to get publication urls for \n",
    "#          critic reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.a SELECT URLS FROM DATABASE TABLE: metacritic_review_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "\n",
    "def select_from_tbl_metacritic_review_urls():\n",
    "    \n",
    "    metacritic_review_urls = dict()\n",
    "    \n",
    "    try:\n",
    "        conn = get_conn_rds()\n",
    "        cursor = conn.cursor()\n",
    "        select_query = \"select * from public.metacritic_review_urls\"\n",
    "        cursor.execute(select_query)\n",
    "        print(\"Selecting rows from the table using cursor.fetchall\")\n",
    "        result_set = cursor.fetchall() \n",
    "   \n",
    "        for row in result_set:\n",
    "            metacritic_review_urls[row[0]]= row[1]\n",
    "            \n",
    "       \n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"Error while fetching data from PostgreSQL\", error)\n",
    "\n",
    "    finally:\n",
    "    #closing database connection.\n",
    "        if(conn):\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "    \n",
    "    return metacritic_review_urls\n",
    "\n",
    "\n",
    "result_dict = select_from_tbl_metacritic_review_urls()\n",
    "for key, value in result_dict.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.b INSERT INTO TABLE: publication_urls to be used by: fetchandinsert_publication_urls_per_metacritic_url. \n",
    "##     Please see 2.c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "\n",
    "def insert_to_tbl_publication_urls(metacritic_id, pub_href, username):\n",
    "    try:\n",
    "        conn = get_conn_rds()\n",
    "        cur = conn.cursor()\n",
    "        query_params_list = {'metacritic_id' : metacritic_id,\n",
    "                             'pub_href': pub_href, \n",
    "                             'date_created': datetime.datetime.now(),\n",
    "                             'date_updated': datetime.datetime.now(),\n",
    "                             'username': username}\n",
    "        sql = '''\n",
    "                INSERT INTO public.\"publication_urls\"(metacritic_id, pub_href, date_created, date_updated, username)\n",
    "                        VALUES (%(metacritic_id)s, %(pub_href)s, %(date_created)s, %(date_updated)s, %(username)s);\n",
    "                '''\n",
    "        \n",
    "        cur.execute(sql, query_params_list)\n",
    "\n",
    "        conn.commit()\n",
    "        \n",
    "        print(\"Successfully inserted a record\")\n",
    "\n",
    "        cur.close()\n",
    "        \n",
    "        print(\"Closing Connection.\")\n",
    "    \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STPE 3 - Method to fetch the publication urls per metacritic review url.\n",
    "##     Makes use of methods: 2.a and 2.b.\n",
    "##     Please note the time.sleep - we'll need to pause a while to not be aggressive.\n",
    "##     If scraping night time, these could be relaxed, say commenting inner for loop sleep \n",
    "##     and changing outer for loop sleep to 60 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pub_links =[]\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "def fetchandinsert_publication_urls_per_metacritic_url():\n",
    "    \n",
    "    metacritic_review_urls = select_from_tbl_metacritic_review_urls()  \n",
    "        \n",
    "    browser = webdriver.Chrome(\"/home/srini/pyprjs/scrpr/chromedriver\", options=options)\n",
    "    for metacritic_id, metacritic_href in metacritic_review_urls.items():\n",
    "            browser.get(metacritic_href)\n",
    "            webElem = browser.find_elements_by_css_selector(\"a.read_full\")\n",
    "            for elem in webElem:\n",
    "                pub_href = elem.get_attribute('href')\n",
    "                insert_to_tbl_publication_urls(metacritic_id, pub_href, 'Srini')\n",
    "                pub_links.append(pub_href)\n",
    "                time.sleep(60)\n",
    "            time.sleep(120)\n",
    "        \n",
    "    \n",
    "fetchandinsert_publication_urls_per_metacritic_url()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below two files are the csv exports for review of the data from above two tables: \n",
    "# metacritic_review_urls,\n",
    "# publication_urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 srini srini  16K Apr 30 22:17 metacritic_review_urls_table_export.csv\r\n",
      "-rw-r--r-- 1 srini srini 354K Apr 30 22:18 publication_urls_table_export.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lrth *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 - tested it out on one url. And this method will change to read publication_url one by one from table:\n",
    "#          publication_urls and extract <p> tags for paragraphs on each of the publication_url,\n",
    "#          i.e publication site and the extracted paragraphs will be inserted into the new database table: \n",
    "#          pub_review_paragraphs (this still needs to be created and below method refactored for the storing \n",
    "#          paragraph text into it.\n",
    "#          After each pub_url is scraped, we set is_scraped to True - to track completion.\n",
    "#          We don't need to track is_scraped on metacritic_review_urls table as we're only interested in the \n",
    "#          count for publication urls scraped for tracking purpose. just as a stat for training data.\n",
    "#          Process goes on until all are completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def pub_links_scrape_review():\n",
    "    for link in pub_links[1:2]:\n",
    "        print(link)\n",
    "        response = requests.get(link)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Failed to get HTML:\", response.status_code, response.reason, link)\n",
    "        exit()\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, \"html5lib\")\n",
    "    for ptag in soup.find_all('p'):\n",
    "        if len(ptag.text) > 100:\n",
    "            print(ptag.text)\n",
    "        \n",
    "pub_links_scrape_review()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
